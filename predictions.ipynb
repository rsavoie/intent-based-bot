{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you could test a pretrained model with real sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramiro/bin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from intentbasedbot import text_features as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = 'origenes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_encoder(company_name):\n",
    "\t# base_path = app.root_path\n",
    "\tbase_path = os.path.join(os.getcwd(), 'dist')\n",
    "\n",
    "\t# Model definition\n",
    "\tmodel_path = os.path.join(base_path, 'models', f'model_{company_name}.json')\n",
    "\tlogger.info(f'Loading model from {model_path}')\n",
    "\twith open(model_path, 'r') as json_file:\n",
    "\t\tmodel = model_from_json(json_file.read())\n",
    "\tlogger.info('Model definition loaded from disk')\n",
    "\n",
    "\t# Model weights\n",
    "\tweights_path = os.path.join(base_path, 'models', f'model_{company_name}.h5')\n",
    "\tlogger.info(f'Loading weights from {weights_path}')\n",
    "\tmodel.load_weights(weights_path)\n",
    "\tlogger.info(\"Model weights loaded from disk\")\n",
    "\n",
    "\t# Encoder\n",
    "\tencoder_path = os.path.join(base_path, 'models', f'classes_{company_name}.npy')\n",
    "\tlogger.info(f'Loading encoder from {encoder_path}')\n",
    "\tencoder = LabelEncoder()\n",
    "\tencoder.classes_ = np.load(encoder_path)\n",
    "\tlogger.info('Encoder definition loaded from disk')\n",
    "\n",
    "\t# Tokenizer\n",
    "\ttokenizer_path = os.path.join(base_path, 'models', f'tokenizer_{company_name}.pickle')\n",
    "\twith open(tokenizer_path, 'rb') as handle:\n",
    "\t\ttokenizer = pickle.load(handle)\n",
    "\n",
    "\treturn model, encoder, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentences, tokenizer, max_len = 152):\n",
    "\t\"\"\"\n",
    "\t\t:sentences: List of strings\n",
    "\t\t:returns: (1,100) numpy array\n",
    "\t\"\"\"\n",
    "\tsequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "\t# Transforming the list of indexes to a 2D tensor (sample, maxlen)\n",
    "\treturn pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model from /home/ramiro/AnacondaProjects/Leadaki/intent-based-bot/dist/models/model_origenes.json\n",
      "INFO:root:Model definition loaded from disk\n",
      "INFO:root:Loading weights from /home/ramiro/AnacondaProjects/Leadaki/intent-based-bot/dist/models/model_origenes.h5\n",
      "INFO:root:Model weights loaded from disk\n",
      "INFO:root:Loading encoder from /home/ramiro/AnacondaProjects/Leadaki/intent-based-bot/dist/models/classes_origenes.npy\n",
      "INFO:root:Encoder definition loaded from disk\n"
     ]
    }
   ],
   "source": [
    "model, encoder, tokenizer = get_model_and_encoder(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_utterance = lambda utterance: [token for token in tf.filter_tokenize(utterance) if token not in tf.get_stop_words_es()]\n",
    "tokenize_batch = lambda utterances: [' '.join(tokenize_utterance(utterance)) for utterance in utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    'hola muy buenos dias quiero sacar un seguro de vida para mi mama y para mi',\n",
    "    'quiero saber si estamos cubiertos',\n",
    "    'me robaron el celular en constitucion'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = preprocessing(tokenize_batch(utterances), tokenizer)\n",
    "predictions = model.predict_classes(test_data, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for hola muy buenos dias quiero sacar un seguro de vida para mi mama y para mi: seguro vida\n",
      "Class for quiero saber si estamos cubiertos: solicitud informacion\n",
      "Class for me robaron el celular en constitucion: robo celular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramiro/bin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/ramiro/bin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/ramiro/bin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(predictions)):\n",
    "    print('Class for {}: {}'.format(utterances[i], encoder.inverse_transform(predictions[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
