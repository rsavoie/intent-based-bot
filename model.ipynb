{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for predict the intent based on Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "etbA24J2Xxhe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model hyperparameters\n",
    "dataset_path = 'data/snips_utterances.csv'\n",
    "intent_column = 'Intention'\n",
    "\n",
    "language = 'English'\n",
    "# language = 'Spanish'\n",
    "\n",
    "# Cutting the utterances in this length\n",
    "max_len = 100\n",
    "# Max of the dataset\n",
    "# all_intents_df[language].str.len().max()\n",
    "\n",
    "# Over the 'max_words' most frequent words.\n",
    "max_words = 10000\n",
    "\n",
    "# Dimensions of the selected Embedding\n",
    "embedding_dim = 100\n",
    "# embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Dataset', dataset_path)\n",
    "all_intents_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intents_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "wnus8bouXxiQ",
    "outputId": "54fa5eba-3364-4acb-aeb0-fea33622a2a9"
   },
   "outputs": [],
   "source": [
    "print('Checking balancing of classes')\n",
    "all_intents_df[intent_column].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "91d1p_BwXxid"
   },
   "outputs": [],
   "source": [
    "print('Shuffling the dataset (intents come ordered)')\n",
    "all_intents_df = shuffle(all_intents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "QP-s5AudXxii",
    "outputId": "304023cc-0ac6-4c4b-fcbb-3598431347f5"
   },
   "outputs": [],
   "source": [
    "print('Random sentence')\n",
    "all_intents_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "Fspfsn62Xxit"
   },
   "outputs": [],
   "source": [
    "print(f'Converting dataframe columns \"{language}\" and \"{intent_column}\" into lists')\n",
    "sentences_list = all_intents_df[language].tolist()\n",
    "intents_list = all_intents_df[intent_column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "jlTaU9GHXxiz",
    "outputId": "8a056fbb-5e86-4118-f960-5386eb75625e"
   },
   "outputs": [],
   "source": [
    "print('Checking the size of the lists', (len(sentences_list), len(intents_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and padding of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer(sentences_list, max_words=10000, test_word='book'):\n",
    "    \"\"\"\n",
    "        Fit a Keras Tokenizer based on sentences_list\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(sentences_list)\n",
    "    \n",
    "    # Internal word_index of the tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    print('Vocabulary of the corpora', len(word_index))\n",
    "    print(f'Index of the word {test_word}', word_index[test_word])\n",
    "    \n",
    "    # TODO Save this tokenizer for predictions\n",
    "    with open('dist/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('Tokenizer saved')\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "eMGelBSWXxi4"
   },
   "outputs": [],
   "source": [
    "tokenizer = fit_tokenizer(sentences_list, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_and_pad_sequences(sentences_list, tokenizer):\n",
    "    print('Converting {} sentences into indices with given tokenizer'.format(len(sentences_list)))\n",
    "    sequences = tokenizer.texts_to_sequences(sentences_list)\n",
    "    print('Checking indices of first word', sequences[0][:10])\n",
    "    \n",
    "    # Transforms the sequences into 2D tensors of shape (sample, maxlen)\n",
    "    # Padding to the right data[0, :]\n",
    "    data = pad_sequences(sequences, maxlen=max_len)\n",
    "    print('Shape of padded sequences', data.shape)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "JKHCoB_9XxjT",
    "outputId": "e0b7428f-6c6d-4d10-e8aa-078cbeb7c02f"
   },
   "outputs": [],
   "source": [
    "data = vectorize_and_pad_sequences(sentences_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding and one hot of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoder(intents_list):\n",
    "    \"\"\"\n",
    "        Fit a Sklearn LabelEncoder based on intents_list\n",
    "    \"\"\"    \n",
    "    encoder = LabelEncoder()\n",
    "    print('Fitting a LabelEncoder with given target')\n",
    "    encoder.fit(intents_list)    \n",
    "    \n",
    "    print('Found classes', encoder.classes_)\n",
    "    print('Testing encoder', encoder.transform(encoder.classes_))\n",
    "    \n",
    "    np.save('dist/classes.npy', encoder.classes_)\n",
    "    print('Encoder saved')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = fit_encoder(intents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_one_hot_target(intents_list, encoder):\n",
    "    print('Encoding target with given encoder')\n",
    "    intents_encoded = encoder.transform(intents_list)\n",
    "\n",
    "    print('Convert encoded classes integers to dummy variables')\n",
    "    intents_one_hot = to_categorical(intents_encoded)\n",
    "    \n",
    "    print('Target final shape', intents_one_hot.shape)\n",
    "    return intents_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_one_hot = encode_and_one_hot_target(intents_list, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "sAoN39j-XxkT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, intents_one_hot, random_state=1, test_size = .33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "TYkm8e0vXxkk",
    "outputId": "90dfc4b3-812d-436f-84da-f040366980fd"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "sABXzSoMXxkr",
    "outputId": "fd77c701-ee78-4a4e-eff4-3b7faea48e58"
   },
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVy82RKSXxk2"
   },
   "source": [
    "## Embedding initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.es.300.vec\n",
    "def get_embedding(dim_size = 100, test_word='book'):\n",
    "    \"\"\"\n",
    "        Builds a dictionary {'token': [embedding vector]}\n",
    "        :dim_size: Could be 50, 100, 200, 300\n",
    "    \"\"\"\n",
    "    embedding_file_name = f'glove.6B.{dim_size}d.txt'\n",
    "    # embedding_file_name = f'cc.es.{dim_size}.vec'\n",
    "    embedding_path = os.path.join(os.getcwd(), 'embeddings', embedding_file_name)\n",
    "    print('Will load the following embedding', embedding_file_name)\n",
    "    embeddings_index = {}\n",
    "    with open(os.path.join(os.getcwd(), 'embeddings', embedding_file_name)) as embedding_file:\n",
    "        for embedding_line in embedding_file.readlines():\n",
    "            token = embedding_line.split()[0]\n",
    "            vector = np.asarray(embedding_line.split()[1:], dtype='float32') # Toda su representacion como Embedding\n",
    "            embeddings_index[token] = vector\n",
    "    \n",
    "    print('Found {} word vectors.'.format(len(embeddings_index)))\n",
    "    print('Checking shape', embeddings_index['sandberger'].shape)\n",
    "    # print('Checking vector', embeddings_index['sandberger'][:100])\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "8Jy978iaXxlH"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# First version\n",
    "# Construye un diccionario {'token': [embedding values]}\n",
    "# embeddings_index = {}\n",
    "# f = open(embedding_path)\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0] # Es el token\n",
    "#     coefs = np.asarray(values[1:], dtype='float32') # Toda su representacion como Embedding\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embeddings_index = get_embedding(dim_size = embedding_dim, test_word = 'libro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(max_words, tokenizer):\n",
    "    # Building the matrix for feed the embedding, has to be of shape (max_words, embedding_dim)\n",
    "    embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "    print('Initalizing zeros matrix of shape', embedding_matrix.shape)\n",
    "    \n",
    "    # tokenizer.word_index, el diccionario que definimos antes en el tokenizador con (token, indice)\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        # Para no pasarnos del indice 10.000\n",
    "        if i < max_words:\n",
    "            # Buscamos la palabra en el embedding index\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            # Las palabras que no encontramos en el embedding van a ser todos cero\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    print('Checking representation of word 123', embedding_matrix[123][:100])\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = build_embedding_matrix(max_words, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7Xumu8vXxml"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "FFg8dEGLXxmm",
    "outputId": "9640db5e-bea4-4d40-941f-fd82a42f2202"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "7kuWSHtUXxnE"
   },
   "outputs": [],
   "source": [
    "# Conocimiento de la capa, cada fila es la palabra con el indice i\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "Mjfg-d5pXxnJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "h5GvVBCOXxnV",
    "outputId": "9df4957f-54a1-4b13-8b2c-439a92326bfa"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "t8vbnkc2Xxnd",
    "outputId": "5ba9ed9e-2ce9-4d8a-9261-2450d556b06c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"dist/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"dist/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_figure(training_values, validation_values, metric):\n",
    "    # Usamos un range para generar una serie entera\n",
    "    epochs = range(1, len(training_values) + 1)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(epochs, training_values, 'bo', label='Training ' + metric) # bo es blue dot\n",
    "    plt.plot(epochs, validation_values, 'b', label='Validation ' + metric)\n",
    "    plt.title('Training and validation ' + metric)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss(history):\n",
    "    history_dict = history.history\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    \n",
    "    print_figure(loss_values, val_loss_values, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc(history):\n",
    "    history_dict = history.history\n",
    "    acc_values = history_dict['acc']\n",
    "    val_acc_values = history_dict['val_acc']\n",
    "    \n",
    "    print_figure(acc_values, val_acc_values, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "Ga-3wYn4Xxn3"
   },
   "outputs": [],
   "source": [
    "# test_loss, test_acc\n",
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Desafio II.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
